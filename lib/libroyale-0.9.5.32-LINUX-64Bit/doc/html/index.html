<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>Project Royale: Main Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Project Royale
   </div>
   <div id="projectbrief">powerful software framework for time-of-flight cameras</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Properties</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Macros</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Project Royale Documentation</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>The <b>Royale</b> software package provides a light-weight camera framework for time-of-flight (ToF) cameras. While being tailored to PMD cameras, the framework enables partners and customers to evaluate and/or integrate 3D TOF technology on/in their target platform. This reduces time to first demo and time to market.</p>
<p>Royale contains all the logic which is required to operate a ToF based camera. The user need not care about setting registers, but can conveniently control the camera via a high-level interface. The Royale framework is completely designed in C++ using the C++11 standard.</p>
<p>Royale officially supports the <b>CamBoard pico flexx</b> camera.</p>
<p>on the following platforms:</p>
<ul>
<li>Windows 7/8</li>
<li>Linux (tested on Ubuntu 14.04)</li>
<li>OS X (tested on Yosemite 10.10.4)</li>
<li>Android (tested on Android 4.4.2, currently not running on all Android 5 images)</li>
</ul>
<h1>Getting Started </h1>
<p>Plug in your supported PMD camera to a free USB port of your target device. For some Android devices you may need a powered USB hub for proper usage. For Windows-based systems, please install the low-level camera driver which is part of the delivery package. For Linux-based systems, make sure that you have proper permissions to the USB device. The installation package contains a proper rules file which can be used. For more details, please see the drivers/udev/README file (for Linux distributions).</p>
<p>Once the camera is attached to a free USB port, and the drivers are in place, you may start the <b>royaleviewer</b> application which gives you a first indication, if the camera is working on your target system. The royaleviewer displays a 2D or a 3D representation of the captured depth data. By clicking on the <em>Start</em> button, the capture mode is started and you should see a colored depth map.</p>
<p>Depending on the camera type, you have a set of operation modes which can be chosen in the application. An <b>operation mode</b> is a pre-defined set of parameters which represents a certain use case. Please refer to the section "Use Case" further below for detailed information.</p>
<p>The operation mode encodes three different type of information:</p>
<ul>
<li>number of raw frames being captured for generating the depth image</li>
<li>number of frames per seconds</li>
<li>the maximal exposure time for a raw frame capture event</li>
</ul>
<p>A <em>raw frame</em> contains a 12-bit image which is returned from the ToF imager using a single phase measurement. The user typically does not need to set the internals of the ToF imager since Royale is providing this low-level information.</p>
<p>The operation mode is denoted in the following structure:</p>
<p>MODE_S1_S2FPS_S3</p>
<p>where</p>
<p><em>S1</em> is the number of raw images used to generate a depth image, <em>S2</em> is the number for frames per seconds, and <em>S3</em> is the exposure time in microseconds.</p>
<p>An example is <em>MODE_9_10FPS_1000</em> which captures 9 raw frames (8 modulated plus one intensity image) with 10 frames per seconds, and a maximal integration time of 1000 microseconds.</p>
<h2>Access Levels </h2>
<p>Royale offers three different access levels, each one representing a specific user base.</p>
<blockquote class="doxtable">
<p>For eye-safety reasons access for devices labelled as <code>Laser Class 1</code> is only permitted on <code>Level 1</code> and <code>Level 2</code>.</p>
<p></p>
</blockquote>
<ul>
<li><b>Level 1</b> : users are <em>standard users</em> who operate the camera in a default configured way. Only a limited set of functions are exposed which allow the change the behaviour of the camera module. This level is typically used by application developer who want to integrate Royale into their applications serving high quality depth data.</li>
<li><b>Level 2</b> : For experienced users who can also handle raw data in addition to depth data. Users are also allowed to alter internal processing parameters in order to evaluate the depth data generation and optimise for certain use cases. This level is typically used by users who want to evaluate and optimise depth but also raw data.</li>
<li><b>Level 3</b> : Users are highly professional who are working on bringing up new camera modules, and also optimise the internal parameters of the camera module. This mode must be run with caution since it may damage the hardware but also harm your health. This level is restricted to internal employees only and will not be exposed to customers.</li>
</ul>
<h4>Level Activation</h4>
<p>The different user level can be activated via the <code>ICameraDevice</code> Interface by entering the correct access codes on construction via the <code>CameraDeviceManager</code>. <code>Level 1</code> is activated by default, no code is required. <code>Level 2</code> and <code>Level 3</code> can only be activated with a special activation code (two different codes, one for each level). The higher level also inherits all functionality of the lower levels.</p>
<h2>Use Cases </h2>
<p>For 3D sensing a set of key applications and corresponding use cases have been determined and a corresponding set of processing parameters and camera options have been derived. Those values can only be changed on the 2nd and 3rd level of the <code>ICameraDevice</code> interface.</p>
<blockquote class="doxtable">
<p>Please note that these settings are initial proposals. When investigating your specific application do not hesitate to try a different operation modes, in order to verify whether it provides more beneficial data.</p>
<p></p>
</blockquote>
<table class="doxtable">
<tr>
<th align="center">Nr </th><th align="center">Use Cases </th><th align="center">Operation Modes </th><th align="center">Frequencies </th><th align="center">Range [m] </th><th align="center">Framerate </th><th align="center">Time (us)  </th></tr>
<tr>
<td align="center">1 </td><td align="center">Indoor room reconstruction </td><td align="center">MODE_9_5FPS_2000 </td><td align="center">80 &amp; 60 MHz </td><td align="center">1 - 4.0 </td><td align="center">5 fps </td><td align="center">2000 </td></tr>
<tr>
<td align="center">2 </td><td align="center">Room scanning </td><td align="center">MODE_9_10FPS_1000 </td><td align="center">80 &amp; 60 MHz </td><td align="center">1 - 4.0 </td><td align="center">10 fps </td><td align="center">1000 </td></tr>
<tr>
<td align="center"></td><td align="center">indoor navigation </td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr>
<td align="center">3 </td><td align="center">3D object reconstruction </td><td align="center">MODE_9_15FPS_700 </td><td align="center">80 &amp; 60 MHz </td><td align="center">0.5 - 1.5 </td><td align="center">15 fps </td><td align="center">700 </td></tr>
<tr>
<td align="center">4 </td><td align="center">Medium size object </td><td align="center">MODE_9_25FPS_450 </td><td align="center">80 &amp; 60 MHz </td><td align="center">0.3 - 2.0 </td><td align="center">25 fps </td><td align="center">450 </td></tr>
<tr>
<td align="center"></td><td align="center">recognition, </td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr>
<td align="center"></td><td align="center">face reconstruction </td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr>
<td align="center">5 </td><td align="center">Remote collaboration, </td><td align="center">MODE_5_35FPS_600 </td><td align="center">60 MHz </td><td align="center">0.3 - 2.0 </td><td align="center">35 fps </td><td align="center">600 </td></tr>
<tr>
<td align="center"></td><td align="center">step by step instruction, </td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr>
<td align="center"></td><td align="center">table-top gaming </td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr>
<td align="center">6 </td><td align="center">Small object/product </td><td align="center">MODE_5_45FPS_500 </td><td align="center">60 MHz </td><td align="center">0.1 - 1.0 </td><td align="center">45 fps </td><td align="center">500 </td></tr>
<tr>
<td align="center"></td><td align="center">recognition, </td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
<tr>
<td align="center"></td><td align="center">Hand tracking </td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr>
</table>
<ul>
<li><b>Indoor room reconstruction</b> : <b>PMD</b> sensors are a viable solution to locate objects or people inside large environments, such as buildings. This Use-Case is optimized for long range scanning at a maximum data quality. By making use of multiple frequencies the ambiguity range of the sensor signal can be increased by several magnitudes. At the same this sampling methods leads to an increase in data confidence and applications with very high demands in data quality can be realized.</li>
<li><b>Room scanning, indoor navigation</b> : For mapping applications demanding an enhanced situational awareness <b>PMD</b> quick response time are a necessity. These demands are met by increasing the framerate at a minimum cost in data quality.</li>
<li><b>3D object reconstruction</b> : Scanning and Reproduction of man-sized objects in close proximity demands high data confidence equal to environmental mapping. Since in general the objects of interest are in closer proximity, the range requirements and necessary integration time could be lowered in favor of faster scanning speed.</li>
<li><b>Medium size object Recognition, face reconstruction</b> : In general the quality demands of applications in the field of pattern and object recognition are less demanding than metrological applications. On the other hand, a quick system response time is mandatory. Therefore the integration time and correspondingly the data quality is lowered in favor of faster framerates.</li>
<li><b>Remote collaboration, step by step instruction, table-top gaming</b> : For modern gaming and collaborative applications a quick system response is even more important. Since the range requirement can be lowered and the noise performance of <b>PMD</b> sensors is directly related to the object distance, higher framerates at equal data quality can be realized.</li>
<li><b>Small object/product recognition</b> : For hand-size objects and products the necessary range requirements can be further limited and only one scanning frequency is sufficient. Therefore the framerate could be almost doubled and vice versa the overall scanning speed.</li>
<li><b>Hand tracking</b> : The precise detection and recognition of hand gestures in 3D space is very demanding, both in data quality and processing speed. Hence a special Operation Mode has been devised offering optimum setting for this special application.</li>
</ul>
<h1>SDK and Examples </h1>
<p>Besides the royaleviewer.exe application, the package also provides a Royale SDK which can be used to develop applications using the PMD camera.</p>
<p>There are two samples included in the delivery package which should give you a brief overview about the exposed API. The <em>doc</em> directory offers a detailed description of the Royale API which is a good starting point as well.</p>
<p>The Royale framework currently offers capturing in free running mode only. During capturing the exposure time can be altered up to the maximal specified values defined by the operation mode.</p>
<p>The data is provided using a callback based interface. The consumer must register a listener to the camera device and retrieves the depth data. The high-level API consists of the following interfaces:</p>
<ul>
<li><b>ICameraDevice</b> : Main interface which represents the physical camera. The user will mostly work with this interface to talk to the physical camera device.</li>
<li><b>CameraManager</b> : The main component which can query for connected/supported cameras and is able to generate the proper ICameraDevice.</li>
<li><b>CameraStatus</b> : Gives information about the internal state of the system. Most methods will return a proper error code to the caller.</li>
<li><b>IDepthDataListener</b> : Interface which needs to be implemented in order to retrieve the depth data.</li>
<li><b>DepthData</b> : Contains the processed depth data which can be consumed by the user. Furthermore it contains the exposureTimes for all frames within one DepthData</li>
</ul>
<h2>Compilation </h2>
<p>The package contains all necessary headers and libraries including two samples which should provide a first get-in-touch. The samples also contain a CMakeLists.txt file which allows to compile the code on different platforms.</p>
<p>Please note that you need a C++11 compliant compiler:</p>
<ul>
<li>Windows: Visual Studio 2013 or higher</li>
<li>Linux: gcc 4.8 or higher</li>
<li>OS X: gcc 4.8 or higher or clang 6.1 or higher</li>
</ul>
<h3>Linux</h3>
<p>Open up your favorite console:</p>
<div class="fragment"><div class="line">&lt;blockquote&gt;</div>
<div class="line">cd samples/sample1  </div>
<div class="line">mkdir build  </div>
<div class="line">cd build  </div>
<div class="line">cmake ..  </div>
<div class="line">make</div>
<div class="line"></div>
<div class="line">&lt;/blockquote&gt;</div>
</div><!-- fragment --><h3>Windows</h3>
<p>Open up your development shell (e.g. Visual Studio command line):</p>
<div class="fragment"><div class="line">&lt;blockquote&gt;</div>
<div class="line">cd samples/sample1  </div>
<div class="line">mkdir build  </div>
<div class="line">cd build  </div>
<div class="line">cmake ..</div>
<div class="line"></div>
<div class="line">&lt;/blockquote&gt;</div>
</div><!-- fragment --><p>Then open up your generated solution file with your Visual Studio IDE.</p>
<p><b>For Debug builds you also have to set the /MD flag in the properties of your project. Otherwise you might experience crashes. For the samples and the royale-config.cmake this is already set.</b></p>
<h3>OS X</h3>
<p>Open up your favorite console:</p>
<div class="fragment"><div class="line">&lt;blockquote&gt;</div>
<div class="line">cd samples/sample1  </div>
<div class="line">mkdir build  </div>
<div class="line">cd build  </div>
<div class="line">cmake -G Xcode ..  </div>
<div class="line"></div>
<div class="line">&lt;/blockquote&gt;</div>
</div><!-- fragment --><p>Then open up your generated project file with Xcode IDE.</p>
<p>The package also provides a cmake config file for properly building Royale applications. The cmake file can be found under the share directory.</p>
<h3>Requirements</h3>
<p>The package requires to have the libusb available under Linux-based systems.</p>
<h2>Examples </h2>
<p>The following examples demonstrate the current API and its usage.</p>
<h3>Create a CameraDevice</h3>
<p>The physical depth camera module is represented by the <code>ICameraDevice</code>. This object is automatically generated by the <code>CameraManager</code>. During initialization, the correct configuration parameters for the camera module are loaded and the module/imager is initialized. Here is an example for how to instantiate a <code>ICameraDevice</code>:</p>
<div class="fragment"><div class="line">std::unique_ptr&lt;ICameraDevice&gt; camera;</div>
<div class="line">CameraManager manager;</div>
<div class="line"></div>
<div class="line"><span class="keyword">auto</span> connectedCameras = manager.getConnectedCameraList();</div>
<div class="line"></div>
<div class="line"><span class="comment">// get the first found camera, assuming one camera was found</span></div>
<div class="line">camera = manager.createCamera(connectedCameras[0]);</div>
</div><!-- fragment --><h3>Set an OperationMode</h3>
<p>The camera can be operated in pre-defined operation modes. The following code snippet shows, how to set a certain operation mode:</p>
<div class="fragment"><div class="line">camera-&gt;setOperationMode(camera-&gt;getOperationModes()[0]);</div>
</div><!-- fragment --><p>Since the operation mode provides a maximal exposure time, the time can be set during runtime by using the setExposureTime() method. The pre-defined operation modes make sure that eye safety is guaranteed for cameras using laser illumination.</p>
<div class="fragment"><div class="line">camera-&gt;setExposureTime(600);</div>
</div><!-- fragment --><h3>Start Capture Mode</h3>
<p>After setting up the capture mode, the camera can start capturing. Therefore, a listener needs to be registered:</p>
<div class="fragment"><div class="line">camera-&gt;registerDataListener(listener);</div>
</div><!-- fragment --><p>The listener implementation needs to be derived from the following interface:</p>
<div class="fragment"><div class="line"><span class="keyword">class </span>IDepthDataListener</div>
<div class="line">{</div>
<div class="line"><span class="keyword">public</span>:</div>
<div class="line">    <span class="keyword">virtual</span> ~IDepthDataListener() {}</div>
<div class="line">    <span class="keyword">virtual</span> <span class="keywordtype">void</span> onNewData (<span class="keyword">const</span> DepthData * data) = 0;</div>
<div class="line">};</div>
</div><!-- fragment --><p>After registering a listener, the camera capture mode can be started:</p>
<div class="fragment"><div class="line">camera-&gt;startCapture();</div>
</div><!-- fragment --><p>The camera capture mode can be stopped again by the following code:</p>
<div class="fragment"><div class="line">camera-&gt;stopCapture();</div>
</div><!-- fragment --><h3>Data Structure</h3>
<h4>Point Cloud Data</h4>
<p>The Royale framework delivers 3D point cloud data with the following information for each voxel:</p>
<ul>
<li>X/Y/Z coordinates in object space [m]</li>
<li>Grayscale information</li>
<li>Depth noise</li>
<li>Depth confidence</li>
</ul>
<p>The point cloud data is a dense map of those values in order to maintain neighbourhood information. The following data structure is proposed for the 3D point cloud data:</p>
<div class="fragment"><div class="line"><span class="keyword">struct </span>DepthPoint</div>
<div class="line">{</div>
<div class="line">    <span class="keywordtype">float</span> x;                 </div>
<div class="line">    <span class="keywordtype">float</span> y;                 </div>
<div class="line">    <span class="keywordtype">float</span> z;                 </div>
<div class="line">    <span class="keywordtype">float</span> noise;             </div>
<div class="line">    uint16_t grayValue;      </div>
<div class="line">    uint8_t depthConfidence; </div>
<div class="line">};</div>
<div class="line"></div>
<div class="line"><span class="keyword">struct </span>DepthData</div>
<div class="line">{</div>
<div class="line">    <span class="keywordtype">int</span>                       version;         </div>
<div class="line">    std::chrono::milliseconds timeStamp;       </div>
<div class="line">                                               <span class="comment">//   (time since epoch 1970)</span></div>
<div class="line">    uint16_t                  width;           </div>
<div class="line">    uint16_t                  height;          </div>
<div class="line">    std::vector&lt;uint32_t&gt;     exposureTimes;   </div>
<div class="line">                                               <span class="comment">//   CapturedUseCase</span></div>
<div class="line">    std::vector&lt;DepthPoint&gt;   points;          </div>
<div class="line">};</div>
</div><!-- fragment --><h1>Reference </h1>
<p>FAQ: <a href="http://pmdtec.com/picoflexx/">http://pmdtec.com/picoflexx/</a></p>
<h1>License </h1>
<p>See royale_license.txt. Parts of the software covered by this License Agreement (royale_license.txt) is using libusb under LGPL 2.1, QT5.4 under LGPL 3.0 and zlib under zlib license. </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu Sep 3 2015 17:16:06 for Project Royale by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.6
</small></address>
</body>
</html>
